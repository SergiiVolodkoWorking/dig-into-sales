import os.path
import pandas as pd
from BrowserFactory import BrowserFactory
from BookmarkRepo import BookmarkRepo
from LinkedInProfileScrapper import LinkedInProfileScrapper
from LinkedInCompanyScrapper import LinkedInCompanyScrapper
import time
import json

root_folder = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
DATA_FOLDER = os.path.join(root_folder, "data")

def load_config():
    with open('network_mining_config.json') as f:
        return json.load(f)

# def go_back(browser):
#     time.sleep(3)
#     browser.execute_script("window.history.go(-1)")
#     time.sleep(3)

if __name__ == "__main__":
    print("\n\n----------- Script started -----------\n")
    print(" Welcome to the emails scrapper!\n")
    print(" The script will use links generated by the crawler\n")
    print(" It will be visiting LinkedIn profile and current company of every stored contact\n")
    print(" Please make sure you are logged in to LinkedIn in your Firefox\n")
    print(" Scraping parameters can be configured in 'network_mining_config.json'\n")
    print("\n--------------------------------------\n")
    print("Launching...\n")

    config = load_config()
    BATCH_SIZE = config["scrapper_batch_size"]
    bookmark_file = os.path.join(DATA_FOLDER, config["scrapper_bookmark_file_name"])
    target_data_file = os.path.join(DATA_FOLDER, config["scrapper_result_file_name"])

    browser = BrowserFactory.create()
    profileScrapper = LinkedInProfileScrapper(browser)
    companyScrapper = LinkedInCompanyScrapper(browser)
    bookmarkRepo = BookmarkRepo(bookmark_file)

    try:
        bookmark = bookmarkRepo.load_bookmark()
        profileScrapper.go_to_my_connections()
        
        for i in range(bookmark, bookmark + BATCH_SIZE):
            profileScrapper.scroll_to_index(i)
            profileScrapper.open_profile_by_index(i)
            profile = profileScrapper.scrap_contact_info()
            
            print(profile.name, profile.email)
            
            if('/company/' in profile.company_link or
               '/school/' in profile.company_link):
               company_url = profile.company_link + '/about'
               company = companyScrapper.get_company_data(company_url)
               print(company.specialties)
            
        # input("Press ENTER to finish.....")
    finally:
        browser.quit()
        print('The flow is completed.')
